Optimization completed!
Best configuration found:
  n_blocks    = 2
  n_layers    = 3
  hidden_units= 106
  Fitness (RMSE) = 7.85489078852798
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 100)]                0         []                            
                                                                                                  
 dense (Dense)               (None, 106)                  10706     ['input_1[0][0]']             
                                                                                                  
 dense_1 (Dense)             (None, 106)                  11342     ['dense[0][0]']               
                                                                                                  
 dense_2 (Dense)             (None, 106)                  11342     ['dense_1[0][0]']             
                                                                                                  
 dense_3 (Dense)             (None, 101)                  10807     ['dense_2[0][0]']             
                                                                                                  
 lambda (Lambda)             (None, 100)                  0         ['dense_3[0][0]']             
                                                                                                  
 lambda_2 (Lambda)           (None, 100)                  0         ['input_1[0][0]',             
                                                                     'lambda[0][0]']              
                                                                                                  
 dense_4 (Dense)             (None, 106)                  10706     ['lambda_2[0][0]']            
                                                                                                  
 dense_5 (Dense)             (None, 106)                  11342     ['dense_4[0][0]']             
                                                                                                  
 dense_6 (Dense)             (None, 106)                  11342     ['dense_5[0][0]']             
                                                                                                  
 dense_7 (Dense)             (None, 101)                  10807     ['dense_6[0][0]']             
                                                                                                  
 lambda_1 (Lambda)           (None, 1)                    0         ['dense_3[0][0]']             
                                                                                                  
 lambda_4 (Lambda)           (None, 1)                    0         ['dense_7[0][0]']             
                                                                                                  
 add (Add)                   (None, 1)                    0         ['lambda_1[0][0]',            
                                                                     'lambda_4[0][0]']            
                                                                                                  
==================================================================================================
Total params: 88394 (345.29 KB)
Trainable params: 88394 (345.29 KB)
Non-trainable params: 0 (0.00 Byte)






Final model training time: 35.18 seconds
Final model Train RMSE: 3.0309
Final model Test RMSE: 6.9531